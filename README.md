
DeepQA Chatbot
For this project, I use Python.
IDE is the windows version of Pycharm 

Build process about DeepQA Chatbot
Established the project in Pycharm, the marks are the documents I mainly use.

1.	Data folder is used to save corpus data. This folder is detailed in the address of source control. Opening the data folder: The Cornell folder which under red mark is the Cornell movie dialogue corpus, which is the corpus I use. The Samples folder stores the pkl file that converted from the corpus. And the pkl file is the corpus format read by the program.
2.	Save folder is used to save the model parameters which is obtained from training.
3.	Main.py is the main function, which is the entry of training and testing
4.	Chatbot.py is the main parameter program, which includes various parameter adjustment interfaces.
 
Using Cornell film dialogue corpus to train
I firstly using pip install to install dependencies, but I cannot use them in Pycharm. So I install them in PyCharm.
 
Pycharm cannot find the tensorflow module. 
 
So, I install all of them in Pycharm again.

Running main.py directly to start training.
 
Adjusting the model parameters in chatbot.py, which are numEpochs, saveEvery, batchsize,lr and dropout. 
After finishing reading the corpus, the pkl file will be generated by the Cornell corpus in samples folder.
 
After a long time training, there will be a model parameter file in the save/model folder.
 
Chatbot usage
Clicking Run the top of the interface, then clicking edit configuration.
Inputting in the parameters: -- Test
 
Running the main.py after click confirmation. It will generate a model_predictions.txt file in the save / model folder;
This file is the model obtained from the corpus, which is set to predict the response of the file of data/test/samples.txt.
 

If you change the parameters to --test interactive, you can then interactive with the chatbot.
 
Link to source control repository
https://github.com/MidnightWhite/DeepQA-Chatbot.git 

After training, there is a model file is up to 300 MB, which cannot be uploaded to DLE and too big to push to github. So, I upload it to Google Cloud. Here is the link.
https://drive.google.com/open?id=18_8BPr4g_NTyscWDDfvSIbCe3TsPWygA
